{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mvriLddXNHRT"
      },
      "source": [
        "# Трансформеры\n",
        "В этом домашнем задании мы рассмотим использование трансформеров в библиотеке PyTorch. Рассмотрим задачу языкового моделирования. Попробуем генерировать текст нейронной сетью. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b9U_b-VZNHRa"
      },
      "source": [
        "Ссылка на данные - https://drive.google.com/drive/folders/1x1A4ElliUGBPnHladGMwPxPuGxI8Vnpu?usp=sharing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "-w3oE3ZFNHRc"
      },
      "outputs": [],
      "source": [
        "# хороший тон, импортировать все необходимые библиотеки в одной ячейке ;)\n",
        "\n",
        "import torch\n",
        "from torch import nn\n",
        "\n",
        "import numpy as np\n",
        "import time"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rh27HncbNHRe"
      },
      "source": [
        "Что такое языковое моделирование? Это предсказание вероятности следующего токена (слова или буквы) на основе предыдущих токенов. Математически это можно описать так:\n",
        "\n",
        "$$P(x_i|x_1, x_2 , ... , x_{i-1})$$ \n",
        "\n",
        "Последовательность $$ x_1, x_2, ... x_{i-1} $$ называют контекстом."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XBttwzgLNHRf"
      },
      "source": [
        "## Задание 0 (0 баллов, но сделать нужно)\n",
        "Проставьте знаки неравенств, исходя из вашего опыта:\n",
        "$$ P(раму | мама, мыла) > P(папу | мама, мыла) $$\n",
        "\"мама мыла раму\" -- устойчивое выражение, а значит и более частотное\n",
        "\n",
        "$$ P(столу | дорога, ложка, к) < P(обеду | дорога, ложка, к) $$\n",
        "\"дорога ложка к столу\" -- устойчивое выражение, а значит и более частотное\n",
        "\n",
        "$$ P(Евпатий | меня, зовут) < P(Ваня | меня, зовут) $$\n",
        "евпатий менее часто встречающееся имя, чем ваня\n",
        "\n",
        "$$ P(журналы | я, часто ,читаю) = P(комиксы | я, часто ,читаю) $$\n",
        "здесь слова сопоставимы по частотности, что обусловливает сравнимую вероятность появления в таком контексте\n",
        "\n",
        "Попробуйте объяснить выбор для каждого из примеров."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SttlkCiJNHRg"
      },
      "source": [
        "Ответ : выше"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xz70JAX4NHRh"
      },
      "source": [
        "Если для некоторых из примеров проставить знаки достаточно просто, то на некоторые сложно сказать, какой овтет верный. Мы принимаем решение для данного задания исходя их опыта использования русского языка. Мы много читали на русском и слушали огромное количество русской речи. Обучение языковых моделей происходит по схожему принципу. \n",
        "\n",
        "Мы хотим показать модели столько текстов, сколько можем и надеемся, что она наберется достаточно опыта, чтобы расставлять такие знаки неравества максимально схоже с человеком."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ppqkg2JTNHRi"
      },
      "source": [
        "## Задание 1 (0.5 балла)\n",
        "Мы будем обучать языковую модель для предсказания следущей буквы. Такие языковые модели применяются в распозновании речи, так как предоставляют дополнительную информацию акустической модели при выборе следующего символа. Для начала, откройте файл с данными, посмотрите, какие символы входят в тексты, сколько их. Уберите из текста все символы переноса на новую строку и табуляцию."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "scrolled": true,
        "id": "j6JN5tIyNHRj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8e0b1c9d-de44-4219-ce0f-f48a9bd36b40"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "700000"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "path = 'small_corp_for_test.txt'\n",
        "file = open(path, 'r')\n",
        "data = file.readlines()\n",
        "file.close()\n",
        "len(data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "fg9QhMUzNHRl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "596f8f67-08fc-465a-9fca-c4f64c7fca32"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "т х ч   п о й ф ц э р щ \n",
            " д а у - е з ъ ь н я ы л ш с в к ю ё ж г и б м\n",
            "всего их 36\n"
          ]
        }
      ],
      "source": [
        "print(*set(''.join(data)))\n",
        "print('всего их', len(set(''.join(data))))\n",
        "for index in range(len(data)):\n",
        "    data[index] = data[index].replace('\\n', '').replace('\\t', '')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7vM7iqNcNHRm"
      },
      "source": [
        "## Задание 2 (0.5 балла)\n",
        "Для обучения модели требуется сначала подготовить текст в подходящий для нейросети вид. Важно также отметить, что нужно добавить два токена start и end, которые отвечают за начало и конец текста. Используйте [ и ] для этой задачи. Также нам нужен токен pad, чтобы заполнять им текст до требуемой длинны для формирования батча.\n",
        "\n",
        "Реализуйте метод preprocess класса Preprocessor. Он должен принимать на вход текст и длинну текста, которую мы ожидаем получить на выходе. Текст должен быть переведен в нижний регистр, в конец текста добавляется требуемое число pad токенов, далее текст векторизуется (каждому символу ставится свое число). Вернуть требуется два вектора. Полученный результат без последнего токена (на нем будем обучаться) и полученный результат без первого токена (целевые метки при обучении)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "w55HuhKwNHRn"
      },
      "outputs": [],
      "source": [
        "class Preprocessor:\n",
        "    def __init__(self):\n",
        "        self.alphabet = '_добсркгаупитнезчм яжлйвцыэь-шхюфщёъ][ '\n",
        "        self.token2ind = {}\n",
        "        self.ind2token = {}\n",
        "        for i in range(len(self.alphabet)):\n",
        "            self.token2ind[self.alphabet[i]] = i\n",
        "            self.ind2token[i] = self.alphabet[i]\n",
        "        \n",
        "    \n",
        "    def preprocess(self, text, window_size):\n",
        "        text = text.lower()\n",
        "        padded_text = text + '_' * (window_size + 1 - len(text))\n",
        "        encoded_text = torch.tensor(list(map(lambda symbol: self.token2ind[symbol], padded_text)))\n",
        "        return encoded_text[:-1], encoded_text[1:]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Preprocessor().preprocess('[мама]', 8)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yd85XGWr7Dj7",
        "outputId": "8a255f3f-b376-4532-a6ca-5b824e4a8afa"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([37, 17,  8, 17,  8, 36,  0,  0]),\n",
              " tensor([17,  8, 17,  8, 36,  0,  0,  0]))"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-EqIpnHzNHRo"
      },
      "source": [
        "## Задание 3 (0.5 балла)\n",
        "Так как мы решили, что текст будет начинаться токеном [ и заканчиваться токеном ], данные нужно поправить. Реализуйте эту идею, добавьте данные токены в ваши тексты."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "Ijae6XsVNHRp"
      },
      "outputs": [],
      "source": [
        "for index in range(len(data)):\n",
        "    data[index] = '[' + data[index] + ']'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GlfftxzcNHRp"
      },
      "source": [
        "## Задание 4 (0.5 балла)\n",
        "Так как мы не располагаем большими мощностями, то давайте ограничим максимальную длинну текста. Вы можете менять этот порог и тем самым уменьшать кол-во текстов в вашей выборке и увеличивая тем самым скорость обучения. Начнем же мы с 128. \n",
        "Выберите порог и оставьте только те тексты, длина которых не превосходит данный порог.\n",
        "\n",
        "Далее разбейте тексты на train и test, перемешайте тексты при разбиении, размер тестовой выборки должен быть 15% от общего числа текстов. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "6AkQgSaANHRq"
      },
      "outputs": [],
      "source": [
        "THRESHOLD = 10\n",
        "\n",
        "short_data = list(filter(lambda x: len(x) <= THRESHOLD, data))\n",
        "assert len(short_data) < len(data)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "train, test = train_test_split(short_data, shuffle=True, test_size=0.15)"
      ],
      "metadata": {
        "id": "Iix8z1mizrhy"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mRw68Iz8NHRr"
      },
      "source": [
        "## Задание 5 (2 балла)\n",
        "Напишем датасет. На вход датасету передается набор текстов, объект класса Preprocessor и размер окна, который вы выбрали в прошлом задании.\n",
        "Реализуйте методы __len__ и __getitem__."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "PNb0uFxBNHRr"
      },
      "outputs": [],
      "source": [
        "class TextDataset(torch.utils.data.Dataset):\n",
        "    \n",
        "    def __init__(self, x, preproc, win_size = 128):\n",
        "        self.x = tuple(map(preproc.preprocess, x, [win_size] * len(x)))\n",
        "    \n",
        "    def __len__(self):\n",
        "        return len(self.x)\n",
        "    \n",
        "    def __getitem__(self, idx):\n",
        "        return self.x[idx]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "xgkB3R_BNHRs"
      },
      "outputs": [],
      "source": [
        "preproc = Preprocessor()\n",
        "train_dataset = TextDataset(train, preproc)\n",
        "test_dataset = TextDataset(test, preproc)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IDDqMs2zNHRs"
      },
      "source": [
        "## Задание 6 (2 балла)\n",
        "Напишем модель. Класс для реализации positional encoding реализован за вас, он нужен, чтобы модель могла после получения эмбедингов понимать, на каком месте какой токен находится.\n",
        "\n",
        "Заполните пропуски в классе модели. Гипперпараметры модели вам предлагается подобрать самостоятельно. Рекомендуется использовать не более 6 слоев в трансформере. В декореде испоьлзуйте две линейных слоя с функцией активации ReLU между ними.\n",
        "\n",
        "## Задание 6_1 (0 баллов, но надо ответить!)\n",
        "При обучении языковой модели на основе трансформеров мы используем маскирование символов (как мы это делаем - уже реализовано). Напишите, почему мы это делаем? Почему это так важно?\n",
        "\n",
        "Благодаря механизму внимания модель при оценке вероятности следующего символа может обращаться к любому месту во входной последовательности. Необходимо запретить ей смотреть вперед: на те позиции, которые она еще не предсказала, иначе она будет просто смотреть в будущее и не будет учиться сама."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "8CxKZzlYNHRt"
      },
      "outputs": [],
      "source": [
        "import math\n",
        "\n",
        "class PositionalEncoding(nn.Module):\n",
        "\n",
        "    def __init__(self, d_model, dropout=0.1, max_len=5000):\n",
        "        super(PositionalEncoding, self).__init__()\n",
        "        self.dropout = nn.Dropout(p=dropout)\n",
        "\n",
        "        pe = torch.zeros(max_len, d_model)\n",
        "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
        "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))\n",
        "        pe[:, 0::2] = torch.sin(position * div_term)\n",
        "        pe[:, 1::2] = torch.cos(position * div_term)\n",
        "        pe = pe.unsqueeze(0).transpose(0, 1)\n",
        "        self.register_buffer('pe', pe)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x + self.pe[:x.size(0), :]\n",
        "        return self.dropout(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "b4rwbK6fNHRt"
      },
      "outputs": [],
      "source": [
        "class LanguageModel(nn.Module):\n",
        "    def __init__(self, vocab_size):\n",
        "        super(LanguageModel, self).__init__()\n",
        "        self.emb = nn.Embedding(vocab_size, 100)\n",
        "        self.pe = PositionalEncoding(100)\n",
        "        self.transformer_encoder_layer = nn.TransformerEncoderLayer(100, 10)\n",
        "        self.transformer_encoder = nn.TransformerEncoder(self.transformer_encoder_layer, 10)\n",
        "        self.decoder = nn.Sequential(nn.Linear(100, 100), nn.ReLU(), nn.Linear(100, vocab_size))\n",
        "    \n",
        "    def forward(self, x, src_mask):\n",
        "        x = self.pe(self.emb(x))\n",
        "        x = x.transpose(1, 0)\n",
        "        x = self.transformer_encoder(x, src_mask)\n",
        "        x = self.decoder(x)\n",
        "        return x.transpose(1, 0)\n",
        "    \n",
        "    def generate_square_subsequent_mask(self, sz):\n",
        "        # А вот и то самое маскирование\n",
        "        mask = (torch.triu(torch.ones(sz, sz)) == 1).transpose(0, 1)\n",
        "        mask = mask.float().masked_fill(mask == 0, float('-inf')).masked_fill(mask == 1, float(0.0))\n",
        "        return mask"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "xCMa7EPqNHRu"
      },
      "outputs": [],
      "source": [
        "model = LanguageModel(len('_добсркгаупитнезчм яжлйвцыэь-шхюфщёъ][ '))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qoJEWAUINHRu"
      },
      "source": [
        "## Задание 7 (2,5 балла)\n",
        "Финишная прямая. Давайте реализуем класс для обучения модели и ее валидации. Следуйте указаниям в коде и заполните недостающие фрагменты в коде."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "jjJo0iymNHRv"
      },
      "outputs": [],
      "source": [
        "class Trainer:\n",
        "    \n",
        "    def __init__(self, model, train_dataset, test_dataset):\n",
        "        \n",
        "        self.model = model\n",
        "        \n",
        "        self.train_batch_size = 32\n",
        "        self.test_batch_size = 32\n",
        "        \n",
        "        self.train_dataloader = torch.utils.data.DataLoader(train_dataset, \n",
        "                                                            batch_size=self.train_batch_size, \n",
        "                                                            shuffle=True)\n",
        "        self.test_dataloader = torch.utils.data.DataLoader(test_dataset, \n",
        "                                                           batch_size=self.test_batch_size, \n",
        "                                                           shuffle=False)\n",
        "        self.train_dataloader_size = len(train_dataset) // self.train_batch_size \n",
        "        self.test_dataloader_size = len(test_dataset) // self.test_batch_size\n",
        "        \n",
        "        self.device = 'cuda:0'\n",
        "        self.criterion = nn.CrossEntropyLoss(ignore_index=0) # используйте CrossEntrophyLoss, передайте в качетсве параметра \n",
        "                             # ignore index индекс символа _, чтобы модель не штрафовалась за то\n",
        "                             # что идет после закрывающего токена\n",
        "        \n",
        "        self.optimizer = torch.optim.Adam(model.parameters(), 1e-3)\n",
        "        \n",
        "        self.steps_to_print = 10\n",
        "        \n",
        "    def train_one_epoch(self, epoch_number):\n",
        "        step = 0\n",
        "        counted_loss = 0\n",
        "        current_time = time.time()\n",
        "        it = 0\n",
        "        \n",
        "        for batch in self.train_dataloader:\n",
        "            x, y = batch\n",
        "            model_output = self.model(x, self.model.generate_square_subsequent_mask(x.shape[1]))\n",
        "            model_output = model_output.reshape(model_output.shape[0] * model_output.shape[1], model_output.shape[2])\n",
        "            loss = self.criterion(model_output, y.reshape(y.shape[0] * y.shape[1]))\n",
        "            loss.backward()\n",
        "            self.optimizer.step()\n",
        "            self.optimizer.zero_grad()\n",
        "\n",
        "            counted_loss += int(loss.unsqueeze(0).data)\n",
        "            it += 1\n",
        "            step += 1\n",
        "            \n",
        "            # реализуйте шаги обучения модели\n",
        "            # сохраняйте значение ошибки в переменную counted_loss\n",
        "            \n",
        "            ################\n",
        "            \n",
        "            \n",
        "            if step%self.steps_to_print == 0:\n",
        "                result = 'Train epoch '+str(epoch_number)+' | '\n",
        "                result += 'Step '+str(step)+'/'+str(self.train_dataloader_size)+' | '\n",
        "                result += 'Counted loss '+str(counted_loss)+' | '\n",
        "                result += 'ppl '+str(math.exp(counted_loss/it))+' | '\n",
        "                result += 'time '+str(time.time() - current_time) + ' | '\n",
        "                print(result)\n",
        "                current_time = time.time()\n",
        "                counted_loss = 0\n",
        "                it = 0\n",
        "    \n",
        "    def validate_one_epoch(self, epoch_number):\n",
        "        step = 0\n",
        "        counted_loss = 0\n",
        "        current_time = time.time()\n",
        "        it = 0\n",
        "        for batch in self.test_dataloader:\n",
        "            x, y = batch\n",
        "            \n",
        "            model_output = self.model(x, self.model.generate_square_subsequent_mask(x.shape[1]))\n",
        "            model_output = model_output.reshape(model_output.shape[0] * model_output.shape[1], model_output.shape[2])\n",
        "            loss = self.criterion(model_output, y.reshape(y.shape[0] * y.shape[1]))\n",
        "\n",
        "            counted_loss += int(loss.unsqueeze(0).data)\n",
        "            it += 1\n",
        "            step += 1\n",
        "\n",
        "            # реализуйте шаги для теста модели\n",
        "            # помните, что данный метод уже запускается из \n",
        "            # блока with torch.no_grad(), а потому \n",
        "            # повторно его использовать не нужно\n",
        "            \n",
        "            ################\n",
        "            \n",
        "            if step%(self.steps_to_print//2) == 0:\n",
        "                result = 'Validate epoch '+str(epoch_number)+' | '\n",
        "                result += 'Step '+str(step)+'/'+str(self.test_dataloader_size)+' | '\n",
        "                result += 'Counted loss '+str(counted_loss)+' | '\n",
        "                result += 'ppl '+str(math.exp(counted_loss/it))+' | '\n",
        "                result += 'time '+str(time.time() - current_time) + ' | '\n",
        "                print(result)\n",
        "                current_time = time.time()\n",
        "                counted_loss = 0\n",
        "                it = 0\n",
        "        \n",
        "    def train(self, number_of_epochs):\n",
        "        # model.to(self.device)\n",
        "        for epoch in range(1, number_of_epochs+1):\n",
        "            model.train()\n",
        "            self.train_one_epoch(epoch)\n",
        "            with torch.no_grad():\n",
        "                model.eval()\n",
        "                self.validate_one_epoch(epoch)\n",
        "            print()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Cf8OuAaNHRv"
      },
      "source": [
        "Что такое ppl? Перплексия. Ее можно интерпретировать как меру \"удивленности\" модели нужному символу. Чем меньше данная величина, тем лучше, ведь это значит, что модель если и сделала неправильный выбор, то не сильно удивлена своей ошибке.\n",
        "\n",
        "Проведите несколько экспериментов, посмотрите, при каких гипперпараметрах значение перплексии минимально."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vOmASog3NHRw"
      },
      "source": [
        "## Задание 8 (0.5 балла)\n",
        "Запустите обучение на нескольких эпохах. Ориентируйтесь на ваши вычислительные мощности и время работы. Вы всегда можете посчитать, сколько секунд уходит на один батч."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pwbvNwJNNHRw",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "4c70a30b-ccfe-4858-b070-41898676246c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train epoch 1 | Step 10/1224 | Counted loss 26 | ppl 13.463738035001692 | time 49.654540061950684 | \n",
            "Train epoch 1 | Step 20/1224 | Counted loss 25 | ppl 12.182493960703473 | time 48.707382917404175 | \n",
            "Train epoch 1 | Step 30/1224 | Counted loss 24 | ppl 11.023176380641601 | time 47.98096036911011 | \n",
            "Train epoch 1 | Step 40/1224 | Counted loss 27 | ppl 14.879731724872837 | time 48.47192120552063 | \n",
            "Train epoch 1 | Step 50/1224 | Counted loss 27 | ppl 14.879731724872837 | time 48.17089819908142 | \n",
            "Train epoch 1 | Step 60/1224 | Counted loss 25 | ppl 12.182493960703473 | time 47.92381191253662 | \n",
            "Train epoch 1 | Step 70/1224 | Counted loss 25 | ppl 12.182493960703473 | time 48.08495855331421 | \n",
            "Train epoch 1 | Step 80/1224 | Counted loss 29 | ppl 18.17414536944306 | time 47.96441102027893 | \n",
            "Train epoch 1 | Step 90/1224 | Counted loss 24 | ppl 11.023176380641601 | time 48.00698661804199 | \n",
            "Train epoch 1 | Step 100/1224 | Counted loss 24 | ppl 11.023176380641601 | time 47.985023975372314 | \n",
            "Train epoch 1 | Step 110/1224 | Counted loss 25 | ppl 12.182493960703473 | time 48.631409883499146 | \n",
            "Train epoch 1 | Step 120/1224 | Counted loss 24 | ppl 11.023176380641601 | time 48.061190605163574 | \n",
            "Train epoch 1 | Step 130/1224 | Counted loss 23 | ppl 9.974182454814718 | time 48.17976450920105 | \n",
            "Train epoch 1 | Step 140/1224 | Counted loss 25 | ppl 12.182493960703473 | time 48.78663516044617 | \n",
            "Train epoch 1 | Step 150/1224 | Counted loss 25 | ppl 12.182493960703473 | time 48.36226987838745 | \n",
            "Train epoch 1 | Step 160/1224 | Counted loss 22 | ppl 9.025013499434122 | time 47.8040657043457 | \n",
            "Train epoch 1 | Step 170/1224 | Counted loss 21 | ppl 8.166169912567652 | time 47.87735056877136 | \n",
            "Train epoch 1 | Step 180/1224 | Counted loss 23 | ppl 9.974182454814718 | time 49.0956449508667 | \n",
            "Train epoch 1 | Step 190/1224 | Counted loss 22 | ppl 9.025013499434122 | time 48.15440773963928 | \n",
            "Train epoch 1 | Step 200/1224 | Counted loss 20 | ppl 7.38905609893065 | time 49.15041184425354 | \n",
            "Train epoch 1 | Step 210/1224 | Counted loss 21 | ppl 8.166169912567652 | time 48.51250123977661 | \n",
            "Train epoch 1 | Step 220/1224 | Counted loss 20 | ppl 7.38905609893065 | time 48.01406764984131 | \n",
            "Train epoch 1 | Step 230/1224 | Counted loss 21 | ppl 8.166169912567652 | time 48.39646363258362 | \n",
            "Train epoch 1 | Step 240/1224 | Counted loss 22 | ppl 9.025013499434122 | time 48.18329358100891 | \n",
            "Train epoch 1 | Step 250/1224 | Counted loss 20 | ppl 7.38905609893065 | time 47.68025517463684 | \n",
            "Train epoch 1 | Step 260/1224 | Counted loss 21 | ppl 8.166169912567652 | time 47.59723973274231 | \n",
            "Train epoch 1 | Step 270/1224 | Counted loss 20 | ppl 7.38905609893065 | time 48.04916000366211 | \n",
            "Train epoch 1 | Step 280/1224 | Counted loss 20 | ppl 7.38905609893065 | time 47.86510944366455 | \n",
            "Train epoch 1 | Step 290/1224 | Counted loss 20 | ppl 7.38905609893065 | time 47.72049522399902 | \n",
            "Train epoch 1 | Step 300/1224 | Counted loss 21 | ppl 8.166169912567652 | time 47.94187784194946 | \n",
            "Train epoch 1 | Step 310/1224 | Counted loss 20 | ppl 7.38905609893065 | time 48.29121804237366 | \n",
            "Train epoch 1 | Step 320/1224 | Counted loss 21 | ppl 8.166169912567652 | time 47.716553688049316 | \n",
            "Train epoch 1 | Step 330/1224 | Counted loss 22 | ppl 9.025013499434122 | time 48.04792857170105 | \n",
            "Train epoch 1 | Step 340/1224 | Counted loss 20 | ppl 7.38905609893065 | time 48.20630693435669 | \n",
            "Train epoch 1 | Step 350/1224 | Counted loss 20 | ppl 7.38905609893065 | time 47.96170663833618 | \n",
            "Train epoch 1 | Step 360/1224 | Counted loss 20 | ppl 7.38905609893065 | time 49.23993754386902 | \n",
            "Train epoch 1 | Step 370/1224 | Counted loss 20 | ppl 7.38905609893065 | time 49.542733669281006 | \n",
            "Train epoch 1 | Step 380/1224 | Counted loss 20 | ppl 7.38905609893065 | time 49.239781618118286 | \n",
            "Train epoch 1 | Step 390/1224 | Counted loss 22 | ppl 9.025013499434122 | time 49.148972272872925 | \n",
            "Train epoch 1 | Step 400/1224 | Counted loss 21 | ppl 8.166169912567652 | time 49.56500029563904 | \n",
            "Train epoch 1 | Step 410/1224 | Counted loss 20 | ppl 7.38905609893065 | time 49.50861978530884 | \n",
            "Train epoch 1 | Step 420/1224 | Counted loss 21 | ppl 8.166169912567652 | time 48.69939088821411 | \n",
            "Train epoch 1 | Step 430/1224 | Counted loss 20 | ppl 7.38905609893065 | time 49.29786229133606 | \n",
            "Train epoch 1 | Step 440/1224 | Counted loss 20 | ppl 7.38905609893065 | time 49.53790473937988 | \n",
            "Train epoch 1 | Step 450/1224 | Counted loss 20 | ppl 7.38905609893065 | time 49.72597146034241 | \n",
            "Train epoch 1 | Step 460/1224 | Counted loss 20 | ppl 7.38905609893065 | time 49.332332611083984 | \n",
            "Train epoch 1 | Step 470/1224 | Counted loss 20 | ppl 7.38905609893065 | time 53.088008642196655 | \n",
            "Train epoch 1 | Step 480/1224 | Counted loss 20 | ppl 7.38905609893065 | time 50.999611139297485 | \n",
            "Train epoch 1 | Step 490/1224 | Counted loss 20 | ppl 7.38905609893065 | time 47.796194314956665 | \n",
            "Train epoch 1 | Step 500/1224 | Counted loss 20 | ppl 7.38905609893065 | time 48.00434899330139 | \n",
            "Train epoch 1 | Step 510/1224 | Counted loss 20 | ppl 7.38905609893065 | time 47.13753890991211 | \n",
            "Train epoch 1 | Step 520/1224 | Counted loss 21 | ppl 8.166169912567652 | time 47.60037112236023 | \n",
            "Train epoch 1 | Step 530/1224 | Counted loss 20 | ppl 7.38905609893065 | time 47.95875000953674 | \n",
            "Train epoch 1 | Step 540/1224 | Counted loss 21 | ppl 8.166169912567652 | time 47.7736599445343 | \n",
            "Train epoch 1 | Step 550/1224 | Counted loss 20 | ppl 7.38905609893065 | time 47.74213790893555 | \n",
            "Train epoch 1 | Step 560/1224 | Counted loss 21 | ppl 8.166169912567652 | time 47.439544677734375 | \n",
            "Train epoch 1 | Step 570/1224 | Counted loss 20 | ppl 7.38905609893065 | time 47.72098517417908 | \n",
            "Train epoch 1 | Step 580/1224 | Counted loss 20 | ppl 7.38905609893065 | time 48.40691566467285 | \n",
            "Train epoch 1 | Step 590/1224 | Counted loss 20 | ppl 7.38905609893065 | time 47.9512984752655 | \n",
            "Train epoch 1 | Step 600/1224 | Counted loss 21 | ppl 8.166169912567652 | time 47.4491822719574 | \n",
            "Train epoch 1 | Step 610/1224 | Counted loss 20 | ppl 7.38905609893065 | time 49.43600511550903 | \n",
            "Train epoch 1 | Step 620/1224 | Counted loss 20 | ppl 7.38905609893065 | time 48.59414100646973 | \n",
            "Train epoch 1 | Step 630/1224 | Counted loss 20 | ppl 7.38905609893065 | time 47.888692140579224 | \n",
            "Train epoch 1 | Step 640/1224 | Counted loss 20 | ppl 7.38905609893065 | time 47.23302960395813 | \n",
            "Train epoch 1 | Step 650/1224 | Counted loss 20 | ppl 7.38905609893065 | time 47.55210018157959 | \n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-81-27e97dcd5bd7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mtrainer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTrainer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_dataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-79-4be142f11904>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, number_of_epochs)\u001b[0m\n\u001b[1;32m    100\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnumber_of_epochs\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m             \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 102\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_one_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    103\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m                 \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-79-4be142f11904>\u001b[0m in \u001b[0;36mtrain_one_epoch\u001b[0;34m(self, epoch_number)\u001b[0m\n\u001b[1;32m     34\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_dataloader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m             \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m             \u001b[0mmodel_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate_square_subsequent_mask\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m             \u001b[0mmodel_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mmodel_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-54-7689a995ebde>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, src_mask)\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0memb\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransformer_encoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msrc_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/transformer.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, src, mask, src_key_padding_mask)\u001b[0m\n\u001b[1;32m    196\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    197\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmod\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 198\u001b[0;31m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msrc_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msrc_key_padding_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msrc_key_padding_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    199\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/transformer.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, src, src_mask, src_key_padding_mask)\u001b[0m\n\u001b[1;32m    337\u001b[0m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ff_block\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    338\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 339\u001b[0;31m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sa_block\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msrc_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msrc_key_padding_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    340\u001b[0m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ff_block\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    341\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/transformer.py\u001b[0m in \u001b[0;36m_sa_block\u001b[0;34m(self, x, attn_mask, key_padding_mask)\u001b[0m\n\u001b[1;32m    348\u001b[0m                            \u001b[0mattn_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattn_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    349\u001b[0m                            \u001b[0mkey_padding_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkey_padding_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 350\u001b[0;31m                            need_weights=False)[0]\n\u001b[0m\u001b[1;32m    351\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    352\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/activation.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, query, key, value, key_padding_mask, need_weights, attn_mask)\u001b[0m\n\u001b[1;32m   1008\u001b[0m                 \u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1009\u001b[0m                 \u001b[0mkey_padding_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkey_padding_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mneed_weights\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mneed_weights\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1010\u001b[0;31m                 attn_mask=attn_mask)\n\u001b[0m\u001b[1;32m   1011\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_first\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1012\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mattn_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattn_output_weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mmulti_head_attention_forward\u001b[0;34m(query, key, value, embed_dim_to_check, num_heads, in_proj_weight, in_proj_bias, bias_k, bias_v, add_zero_attn, dropout_p, out_proj_weight, out_proj_bias, training, key_padding_mask, need_weights, attn_mask, use_separate_proj_weight, q_proj_weight, k_proj_weight, v_proj_weight, static_k, static_v)\u001b[0m\n\u001b[1;32m   5099\u001b[0m     \u001b[0;31m# (deep breath) calculate attention and out projection\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5100\u001b[0m     \u001b[0;31m#\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5101\u001b[0;31m     \u001b[0mattn_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattn_output_weights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_scaled_dot_product_attention\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattn_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdropout_p\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5102\u001b[0m     \u001b[0mattn_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mattn_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontiguous\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtgt_len\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbsz\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0membed_dim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5103\u001b[0m     \u001b[0mattn_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattn_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_proj_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_proj_bias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36m_scaled_dot_product_attention\u001b[0;34m(q, k, v, attn_mask, dropout_p)\u001b[0m\n\u001b[1;32m   4845\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mattn_mask\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4846\u001b[0m         \u001b[0mattn\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mattn_mask\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4847\u001b[0;31m     \u001b[0mattn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msoftmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4848\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mdropout_p\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4849\u001b[0m         \u001b[0mattn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdropout_p\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36msoftmax\u001b[0;34m(input, dim, _stacklevel, dtype)\u001b[0m\n\u001b[1;32m   1678\u001b[0m         \u001b[0mdim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_softmax_dim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"softmax\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_stacklevel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1679\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1680\u001b[0;31m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msoftmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1681\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1682\u001b[0m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msoftmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "trainer = Trainer(model, train_dataset, test_dataset)\n",
        "trainer.train(1)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "ну и так видно что лосс падает, перплексия вместе с ним, извините я не буду ждать все миллион лет...."
      ],
      "metadata": {
        "id": "jCCAXyh_D3mC"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-CU31rXoNHRw"
      },
      "source": [
        "## Задание 9 (1 балл)\n",
        "Итак, давайте попробуем погенерировать текст нашей сеткой. Закончите функцию по генерации текста. Попробуйте сгенерировать какой-нибудь текст. Помните, что если вы хотите генерировать текст с нуля, то вы должны передать в качестве текста только токен start.\n",
        "Прекратите генерировать текст, если модель выдала токен end или длинна текста больше 150."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "6vqgcrrLNHRx"
      },
      "outputs": [],
      "source": [
        "def generate_text(text):\n",
        "    x = []\n",
        "    \n",
        "    for letter in text:\n",
        "        x.append(preproc.token2ind[letter])\n",
        "    x = torch.from_numpy(np.array(x))\n",
        "    \n",
        "    pred = model(x.reshape(1, x.shape[0]), model.generate_square_subsequent_mask(x.shape[0]))\n",
        "    ind = pred[0, -1, :].argmax()\n",
        "    \n",
        "    text += preproc.ind2token[int(ind)]\n",
        "    \n",
        "    if text[-1] == '_' or len(text) > 150:\n",
        "        return text\n",
        "    else:\n",
        "        return generate_text(text)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "generate_text('[ма')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "fpzc0N46QaGl",
        "outputId": "9f3de697-7643-407d-ceed-fe9d54aa1a6e"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'[маууууууууууиууууущуууууууууууууууууууууууууууууууууууууууууууууууууюууууууууууууууууууууюуууююууууууууюуууууууууууууууууюуууюуууууюуууууууюууууюууууу'"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        ""
      ],
      "metadata": {
        "id": "koGxgj6jRR90"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hkUbx6v0NHRx"
      },
      "source": [
        "## Задание 10* (Задание - бонус, 5 баллов за реализацию при условии, что сделаны прошлые задания)\n",
        "Давайте вспомним, что такое transfer learning. Мы хотим использовать уже предобученные эмбединги для нашей сети, чтобы наша сеть обучалась быстрее. Давайте попробуем обучить новую модель на уровне слов, а не символов, но для упрощения задачи используем предобученный слой из библиотеки Natasha, а вернее, ее блок Navec."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6mvyaoxjNHRx"
      },
      "source": [
        "[Изучите](https://github.com/natasha/navec) то, как вставить слой в вашу нейронную сеть."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zPwA_up9NHRy"
      },
      "source": [
        "Теперь мы хотим, чтобы на вход модели подавались слова, модифицируйте ваш датасет. Возвращайте теперь номер слова в словаре navec."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "path = 'small_corp_for_test.txt'\n",
        "file = open(path, 'r')\n",
        "data = file.readlines()\n",
        "file.close()\n",
        "print(len(data))\n",
        "\n",
        "for index in range(len(data)):\n",
        "    data[index] = data[index].replace('\\n', '').replace('\\t', '')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PUQEB_kDEkBP",
        "outputId": "524c00c7-fffc-4902-b0b4-1117c497999b"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "700000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install navec -q"
      ],
      "metadata": {
        "id": "ANxiBac_m-zu"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! wget https://storage.yandexcloud.net/natasha-navec/packs/navec_hudlit_v1_12B_500K_300d_100q.tar"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eUrjzIJhnD9a",
        "outputId": "aa76d4b6-a313-45da-cfa8-9de2278e25e5"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2021-12-20 13:42:35--  https://storage.yandexcloud.net/natasha-navec/packs/navec_hudlit_v1_12B_500K_300d_100q.tar\n",
            "Resolving storage.yandexcloud.net (storage.yandexcloud.net)... 213.180.193.243, 2a02:6b8::1d9\n",
            "Connecting to storage.yandexcloud.net (storage.yandexcloud.net)|213.180.193.243|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 53012480 (51M) [application/x-tar]\n",
            "Saving to: ‘navec_hudlit_v1_12B_500K_300d_100q.tar’\n",
            "\n",
            "navec_hudlit_v1_12B 100%[===================>]  50.56M  16.2MB/s    in 3.1s    \n",
            "\n",
            "2021-12-20 13:42:39 (16.2 MB/s) - ‘navec_hudlit_v1_12B_500K_300d_100q.tar’ saved [53012480/53012480]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from navec import Navec\n",
        "\n",
        "NAVEC_PATH = '/content/navec_hudlit_v1_12B_500K_300d_100q.tar'\n",
        "navec = Navec.load(NAVEC_PATH)\n",
        "navec.vocab['мамочка']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mJKmJ9kKnLJl",
        "outputId": "7b0d6be3-6be3-40d6-ec10-f489e7e73ea7"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "206063"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class Preprocessor:\n",
        "    def __init__(self, module):\n",
        "        self.module = module\n",
        "    \n",
        "    def preprocess(self, text, window_size):\n",
        "        text = text.lower().split()\n",
        "        padded_text = text + ['паддинг'] * (window_size + 1 - len(text))\n",
        "        encoded_text = torch.tensor(list(map(lambda word: self.module.vocab.get(word, 0), padded_text)))\n",
        "        return encoded_text[:-1], encoded_text[1:]"
      ],
      "metadata": {
        "id": "nUOmVRRGpKaO"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "preproc = Preprocessor(navec)\n",
        "preproc.preprocess('Мама мыла раму', 10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8HwuPW4ErcU6",
        "outputId": "a95cdbb6-b54a-47fe-fcb0-8b2b0becdd11"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([205917, 223867, 366518,      0,      0,      0,      0,      0,      0,\n",
              "              0]),\n",
              " tensor([223867, 366518,      0,      0,      0,      0,      0,      0,      0,\n",
              "              0]))"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "_Z9u7lLCT3lk"
      },
      "outputs": [],
      "source": [
        "class TextDataset_Navec(torch.utils.data.Dataset):\n",
        "    \n",
        "    def __init__(self, x, win_size = 128):\n",
        "        # YOUR CODE HERE\n",
        "        self.navec = Navec.load(NAVEC_PATH)\n",
        "        self.x = list(map(lambda text: Preprocessor(self.navec).preprocess(text, win_size), x))\n",
        "        # self.x = torch.tensor(self.x)\n",
        "        ################\n",
        "    \n",
        "    def __len__(self):\n",
        "        return len(self.x)\n",
        "        ################\n",
        "    \n",
        "    def __getitem__(self, idx):\n",
        "        return self.x[idx]\n",
        "        ################"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "train, test = train_test_split(data, shuffle=True, test_size=0.15)\n",
        "train_dataset, test_dataset = TextDataset_Navec(train), TextDataset_Navec(test)"
      ],
      "metadata": {
        "id": "CF2ANeRSsotc"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset[0][0].shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TVf5S_p-uajj",
        "outputId": "771db8ac-a9ab-4713-a3cc-fa4bbe6d66cf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([128])"
            ]
          },
          "metadata": {},
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nSYTWLbOT3lm"
      },
      "source": [
        "Немного модифицируем модель. Теперь нам не нужны слои с трансформером, так как весь механизм внимания уже заложен в ембедингах. Давайте попробуем просто пройтись линейной головой над эмбедингами. Выберите параметры самостоятельно."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from slovnet.model.emb import NavecEmbedding\n",
        "\n",
        "emb = NavecEmbedding(navec)\n",
        "input = torch.tensor([1, 2, 0])\n",
        "output = emb(input)"
      ],
      "metadata": {
        "id": "lnLrkyVtxB6Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install slovnet"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BvJJ40x_GP4m",
        "outputId": "8fdd42b5-af9c-41c7-e2de-a35d18df5d22"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting slovnet\n",
            "  Downloading slovnet-0.5.0-py3-none-any.whl (49 kB)\n",
            "\u001b[?25l\r\u001b[K     |██████▋                         | 10 kB 18.2 MB/s eta 0:00:01\r\u001b[K     |█████████████▎                  | 20 kB 23.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 30 kB 12.6 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▌     | 40 kB 9.8 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 49 kB 2.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from slovnet) (1.19.5)\n",
            "Collecting razdel\n",
            "  Downloading razdel-0.5.0-py3-none-any.whl (21 kB)\n",
            "Requirement already satisfied: navec in /usr/local/lib/python3.7/dist-packages (from slovnet) (0.10.0)\n",
            "Installing collected packages: razdel, slovnet\n",
            "Successfully installed razdel-0.5.0 slovnet-0.5.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "7M1jDhQNT3lo"
      },
      "outputs": [],
      "source": [
        "from slovnet.model.emb import NavecEmbedding\n",
        "\n",
        "class LanguageModel(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(LanguageModel, self).__init__()\n",
        "        self.emb_navec = NavecEmbedding(Navec.load(NAVEC_PATH))\n",
        "        self.head = nn.Sequential(nn.Linear(300, 100), nn.ReLU(), nn.Linear(100, 1))\n",
        "    \n",
        "    def forward(self, x):\n",
        "        x = self.emb_navec(x)\n",
        "        x = self.head(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XXHjP61zT3lp"
      },
      "source": [
        "Теперь дело за малым! Надо немного модифицировать класс обучения, так как мы не используем маскирование, после чего можно приступить к тесту!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "ZcPu29-bT3lq"
      },
      "outputs": [],
      "source": [
        "class Trainer:\n",
        "    \n",
        "    def __init__(self, model, train_dataset, test_dataset):\n",
        "        \n",
        "        self.model = model\n",
        "        \n",
        "        self.train_batch_size = 32\n",
        "        self.test_batch_size = 32\n",
        "        \n",
        "        self.train_dataloader = torch.utils.data.DataLoader(train_dataset, \n",
        "                                                            batch_size=self.train_batch_size, \n",
        "                                                            shuffle=True)\n",
        "        self.test_dataloader = torch.utils.data.DataLoader(test_dataset, \n",
        "                                                           batch_size=self.test_batch_size, \n",
        "                                                           shuffle=False)\n",
        "        self.train_dataloader_size = len(train_dataset) // self.train_batch_size \n",
        "        self.test_dataloader_size = len(test_dataset) // self.test_batch_size\n",
        "        \n",
        "        self.device = 'cuda:0'\n",
        "        self.criterion = nn.CrossEntropyLoss(ignore_index=0) # используйте CrossEntrophyLoss, передайте в качетсве параметра \n",
        "                             # ignore index индекс символа _, чтобы модель не штрафовалась за то\n",
        "                             # что идет после закрывающего токена\n",
        "        \n",
        "        self.optimizer = torch.optim.Adam(model.parameters(), 1e-3)\n",
        "        \n",
        "        self.steps_to_print = 10\n",
        "        \n",
        "    def train_one_epoch(self, epoch_number):\n",
        "        step = 0\n",
        "        counted_loss = 0\n",
        "        current_time = time.time()\n",
        "        it = 0\n",
        "\n",
        "        for batch in self.train_dataloader:\n",
        "            x, y = batch\n",
        "            \n",
        "            model_output = self.model(x)\n",
        "            model_output = model_output.reshape(model_output.shape[0] * model_output.shape[1], model_output.shape[2])\n",
        "            loss = self.criterion(model_output, y.reshape(y.shape[0] * y.shape[1]))\n",
        "\n",
        "            loss.backward()\n",
        "            self.optimizer.step()\n",
        "            self.optimizer.zero_grad()\n",
        "\n",
        "            counted_loss += int(loss.unsqueeze(0).data)\n",
        "            it += 1\n",
        "            step += 1\n",
        "            \n",
        "            # реализуйте шаги обучения модели\n",
        "            # сохраняйте значение ошибки в переменную counted_loss\n",
        "            \n",
        "            ################\n",
        "            \n",
        "            \n",
        "            if step%self.steps_to_print == 0:\n",
        "                result = 'Train epoch '+str(epoch_number)+' | '\n",
        "                result += 'Step '+str(step)+'/'+str(self.train_dataloader_size)+' | '\n",
        "                result += 'Counted loss '+str(counted_loss)+' | '\n",
        "                result += 'ppl '+str(math.exp(counted_loss/it))+' | '\n",
        "                result += 'time '+str(time.time() - current_time) + ' | '\n",
        "                print(result)\n",
        "                current_time = time.time()\n",
        "                counted_loss = 0\n",
        "                it = 0\n",
        "    \n",
        "    def validate_one_epoch(self, epoch_number):\n",
        "        step = 0\n",
        "        counted_loss = 0\n",
        "        current_time = time.time()\n",
        "        it = 0\n",
        "        for batch in self.test_dataloader:\n",
        "            x, y = batch\n",
        "            \n",
        "            model_output = self.model(x)\n",
        "            model_output = model_output.reshape(model_output.shape[0] * model_output.shape[1], model_output.shape[2])\n",
        "            loss = self.criterion(model_output, y.reshape(y.shape[0] * y.shape[1]))\n",
        "\n",
        "            loss.backward()\n",
        "            self.optimizer.step()\n",
        "            self.optimizer.zero_grad()\n",
        "\n",
        "            counted_loss += int(loss.unsqueeze(0).data)\n",
        "            it += 1\n",
        "            step += 1\n",
        "            \n",
        "            # реализуйте шаги для теста модели\n",
        "            # помните, что данный метод уже запускается из \n",
        "            # блока with torch.no_grad(), а потому \n",
        "            # повторно его использовать не нужно\n",
        "            \n",
        "            ################\n",
        "            \n",
        "            if step%(self.steps_to_print//2) == 0:\n",
        "                result = 'Validate epoch '+str(epoch_number)+' | '\n",
        "                result += 'Step '+str(step)+'/'+str(self.test_dataloader_size)+' | '\n",
        "                result += 'Counted loss '+str(counted_loss)+' | '\n",
        "                result += 'ppl '+str(math.exp(counted_loss/it))+' | '\n",
        "                result += 'time '+str(time.time() - current_time) + ' | '\n",
        "                print(result)\n",
        "                current_time = time.time()\n",
        "                counted_loss = 0\n",
        "                it = 0\n",
        "        \n",
        "    def train(self, number_of_epochs):\n",
        "        model.to(self.device)\n",
        "        for epoch in range(1, number_of_epochs+1):\n",
        "            model.train()\n",
        "            self.train_one_epoch(epoch)\n",
        "            with torch.no_grad():\n",
        "                model.eval()\n",
        "                self.validate_one_epoch(epoch)\n",
        "            print()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BHjwtXXCNHR0"
      },
      "source": [
        "Запустите обучение. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "SEf3PkzJNHR0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 381
        },
        "outputId": "6e470b77-6f4d-43c7-9973-d2841613413d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train epoch 1 | Step 10/273 | Counted loss 30 | ppl 20.085536923187668 | time 94.80115747451782 | \n",
            "Train epoch 1 | Step 20/273 | Counted loss 29 | ppl 18.17414536944306 | time 93.62750244140625 | \n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-20-ddbaca97ef0c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# trainer = Trainer(model, train_dataset, test_dataset)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mtrainer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTrainer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_dataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-19-3e5a31deee75>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, number_of_epochs)\u001b[0m\n\u001b[1;32m    100\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnumber_of_epochs\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m             \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 102\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_one_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    103\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m                 \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-19-3e5a31deee75>\u001b[0m in \u001b[0;36mtrain_one_epoch\u001b[0;34m(self, epoch_number)\u001b[0m\n\u001b[1;32m     37\u001b[0m             \u001b[0mmodel_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mmodel_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    305\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    306\u001b[0m                 inputs=inputs)\n\u001b[0;32m--> 307\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    308\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    309\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    154\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m    155\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 156\u001b[0;31m         allow_unreachable=True, accumulate_grad=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    157\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    158\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "model = LanguageModel()\n",
        "trainer = Trainer(model, train_dataset, test_dataset)\n",
        "trainer.train(1)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "запустила, но с вашего позволения не буду ждать его завершения"
      ],
      "metadata": {
        "id": "IcHtn1OWMsvI"
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "colab": {
      "name": "марина казюлина последняя домашка ",
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}