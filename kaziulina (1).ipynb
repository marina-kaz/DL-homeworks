{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "казюлина",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q_upCOEI3Upu"
      },
      "source": [
        "# Основы глубинного обучения, майнор ИАД\n",
        "\n",
        "## Домашнее задание 1. Введение в PyTorch. Полносвязные нейронные сети.\n",
        "\n",
        "### Общая информация\n",
        "\n",
        "Дата выдачи: 06.10.2021\n",
        "\n",
        "Мягкий дедлайн: 23:59MSK 25.10.2021\n",
        "\n",
        "Жесткий дедлайн: 23:59MSK 28.10.2021\n",
        "\n",
        "### Оценивание и штрафы\n",
        "Максимально допустимая оценка за работу — 10 баллов. За каждый день просрочки снимается 1 балл. Сдавать задание после жёсткого дедлайна сдачи нельзя.\n",
        "\n",
        "Задание выполняется самостоятельно. «Похожие» решения считаются плагиатом и все задействованные студенты (в том числе те, у кого списали) не могут получить за него больше 0 баллов. Если вы нашли решение какого-то из заданий (или его часть) в открытом источнике, необходимо указать ссылку на этот источник в отдельном блоке в конце вашей работы (скорее всего вы будете не единственным, кто это нашел, поэтому чтобы исключить подозрение в плагиате, необходима ссылка на источник).\n",
        "\n",
        "Неэффективная реализация кода может негативно отразиться на оценке.\n",
        "Также оценка может быть снижена за плохо читаемый код и плохо оформленные графики. Все ответы должны сопровождаться кодом или комментариями о том, как они были получены.\n",
        "\n",
        "### О задании\n",
        "\n",
        "В этом задании вам предстоит предсказывать год выпуска песни по некоторым звуковым признакам: [данные](https://archive.ics.uci.edu/ml/datasets/yearpredictionmsd). В ячейках ниже находится код для загрузки данных. Обратите внимание, что обучающая и тестовая выборки располагаются в одном файле, поэтому НЕ меняйте ячейку, в которой производится деление данных."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RI_eoe063VaP"
      },
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import random\n",
        "import warnings\n",
        "\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "%matplotlib inline"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7NgSZeU-7vgj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "00ca6eac-15ea-4d7c-8c71-c9b677abcb89"
      },
      "source": [
        "!wget -O data.txt.zip https://archive.ics.uci.edu/ml/machine-learning-databases/00203/YearPredictionMSD.txt.zip"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2021-10-26 20:45:16--  https://archive.ics.uci.edu/ml/machine-learning-databases/00203/YearPredictionMSD.txt.zip\n",
            "Resolving archive.ics.uci.edu (archive.ics.uci.edu)... 128.195.10.252\n",
            "Connecting to archive.ics.uci.edu (archive.ics.uci.edu)|128.195.10.252|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 211011981 (201M) [application/x-httpd-php]\n",
            "Saving to: ‘data.txt.zip’\n",
            "\n",
            "data.txt.zip        100%[===================>] 201.24M  55.2MB/s    in 4.0s    \n",
            "\n",
            "2021-10-26 20:45:20 (50.1 MB/s) - ‘data.txt.zip’ saved [211011981/211011981]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DSVJZzkJ7zZE",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 247
        },
        "outputId": "26e35e72-89e8-4778-f336-61325bc24265"
      },
      "source": [
        "df = pd.read_csv('data.txt.zip', header=None)\n",
        "df.head()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "      <th>11</th>\n",
              "      <th>12</th>\n",
              "      <th>13</th>\n",
              "      <th>14</th>\n",
              "      <th>15</th>\n",
              "      <th>16</th>\n",
              "      <th>17</th>\n",
              "      <th>18</th>\n",
              "      <th>19</th>\n",
              "      <th>20</th>\n",
              "      <th>21</th>\n",
              "      <th>22</th>\n",
              "      <th>23</th>\n",
              "      <th>24</th>\n",
              "      <th>25</th>\n",
              "      <th>26</th>\n",
              "      <th>27</th>\n",
              "      <th>28</th>\n",
              "      <th>29</th>\n",
              "      <th>30</th>\n",
              "      <th>31</th>\n",
              "      <th>32</th>\n",
              "      <th>33</th>\n",
              "      <th>34</th>\n",
              "      <th>35</th>\n",
              "      <th>36</th>\n",
              "      <th>37</th>\n",
              "      <th>38</th>\n",
              "      <th>39</th>\n",
              "      <th>...</th>\n",
              "      <th>51</th>\n",
              "      <th>52</th>\n",
              "      <th>53</th>\n",
              "      <th>54</th>\n",
              "      <th>55</th>\n",
              "      <th>56</th>\n",
              "      <th>57</th>\n",
              "      <th>58</th>\n",
              "      <th>59</th>\n",
              "      <th>60</th>\n",
              "      <th>61</th>\n",
              "      <th>62</th>\n",
              "      <th>63</th>\n",
              "      <th>64</th>\n",
              "      <th>65</th>\n",
              "      <th>66</th>\n",
              "      <th>67</th>\n",
              "      <th>68</th>\n",
              "      <th>69</th>\n",
              "      <th>70</th>\n",
              "      <th>71</th>\n",
              "      <th>72</th>\n",
              "      <th>73</th>\n",
              "      <th>74</th>\n",
              "      <th>75</th>\n",
              "      <th>76</th>\n",
              "      <th>77</th>\n",
              "      <th>78</th>\n",
              "      <th>79</th>\n",
              "      <th>80</th>\n",
              "      <th>81</th>\n",
              "      <th>82</th>\n",
              "      <th>83</th>\n",
              "      <th>84</th>\n",
              "      <th>85</th>\n",
              "      <th>86</th>\n",
              "      <th>87</th>\n",
              "      <th>88</th>\n",
              "      <th>89</th>\n",
              "      <th>90</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2001</td>\n",
              "      <td>49.94357</td>\n",
              "      <td>21.47114</td>\n",
              "      <td>73.07750</td>\n",
              "      <td>8.74861</td>\n",
              "      <td>-17.40628</td>\n",
              "      <td>-13.09905</td>\n",
              "      <td>-25.01202</td>\n",
              "      <td>-12.23257</td>\n",
              "      <td>7.83089</td>\n",
              "      <td>-2.46783</td>\n",
              "      <td>3.32136</td>\n",
              "      <td>-2.31521</td>\n",
              "      <td>10.20556</td>\n",
              "      <td>611.10913</td>\n",
              "      <td>951.08960</td>\n",
              "      <td>698.11428</td>\n",
              "      <td>408.98485</td>\n",
              "      <td>383.70912</td>\n",
              "      <td>326.51512</td>\n",
              "      <td>238.11327</td>\n",
              "      <td>251.42414</td>\n",
              "      <td>187.17351</td>\n",
              "      <td>100.42652</td>\n",
              "      <td>179.19498</td>\n",
              "      <td>-8.41558</td>\n",
              "      <td>-317.87038</td>\n",
              "      <td>95.86266</td>\n",
              "      <td>48.10259</td>\n",
              "      <td>-95.66303</td>\n",
              "      <td>-18.06215</td>\n",
              "      <td>1.96984</td>\n",
              "      <td>34.42438</td>\n",
              "      <td>11.72670</td>\n",
              "      <td>1.36790</td>\n",
              "      <td>7.79444</td>\n",
              "      <td>-0.36994</td>\n",
              "      <td>-133.67852</td>\n",
              "      <td>-83.26165</td>\n",
              "      <td>-37.29765</td>\n",
              "      <td>...</td>\n",
              "      <td>-25.38187</td>\n",
              "      <td>-3.90772</td>\n",
              "      <td>13.29258</td>\n",
              "      <td>41.55060</td>\n",
              "      <td>-7.26272</td>\n",
              "      <td>-21.00863</td>\n",
              "      <td>105.50848</td>\n",
              "      <td>64.29856</td>\n",
              "      <td>26.08481</td>\n",
              "      <td>-44.59110</td>\n",
              "      <td>-8.30657</td>\n",
              "      <td>7.93706</td>\n",
              "      <td>-10.73660</td>\n",
              "      <td>-95.44766</td>\n",
              "      <td>-82.03307</td>\n",
              "      <td>-35.59194</td>\n",
              "      <td>4.69525</td>\n",
              "      <td>70.95626</td>\n",
              "      <td>28.09139</td>\n",
              "      <td>6.02015</td>\n",
              "      <td>-37.13767</td>\n",
              "      <td>-41.12450</td>\n",
              "      <td>-8.40816</td>\n",
              "      <td>7.19877</td>\n",
              "      <td>-8.60176</td>\n",
              "      <td>-5.90857</td>\n",
              "      <td>-12.32437</td>\n",
              "      <td>14.68734</td>\n",
              "      <td>-54.32125</td>\n",
              "      <td>40.14786</td>\n",
              "      <td>13.01620</td>\n",
              "      <td>-54.40548</td>\n",
              "      <td>58.99367</td>\n",
              "      <td>15.37344</td>\n",
              "      <td>1.11144</td>\n",
              "      <td>-23.08793</td>\n",
              "      <td>68.40795</td>\n",
              "      <td>-1.82223</td>\n",
              "      <td>-27.46348</td>\n",
              "      <td>2.26327</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2001</td>\n",
              "      <td>48.73215</td>\n",
              "      <td>18.42930</td>\n",
              "      <td>70.32679</td>\n",
              "      <td>12.94636</td>\n",
              "      <td>-10.32437</td>\n",
              "      <td>-24.83777</td>\n",
              "      <td>8.76630</td>\n",
              "      <td>-0.92019</td>\n",
              "      <td>18.76548</td>\n",
              "      <td>4.59210</td>\n",
              "      <td>2.21920</td>\n",
              "      <td>0.34006</td>\n",
              "      <td>44.38997</td>\n",
              "      <td>2056.93836</td>\n",
              "      <td>605.40696</td>\n",
              "      <td>457.41175</td>\n",
              "      <td>777.15347</td>\n",
              "      <td>415.64880</td>\n",
              "      <td>746.47775</td>\n",
              "      <td>366.45320</td>\n",
              "      <td>317.82946</td>\n",
              "      <td>273.07917</td>\n",
              "      <td>141.75921</td>\n",
              "      <td>317.35269</td>\n",
              "      <td>19.48271</td>\n",
              "      <td>-65.25496</td>\n",
              "      <td>162.75145</td>\n",
              "      <td>135.00765</td>\n",
              "      <td>-96.28436</td>\n",
              "      <td>-86.87955</td>\n",
              "      <td>17.38087</td>\n",
              "      <td>45.90742</td>\n",
              "      <td>32.49908</td>\n",
              "      <td>-32.85429</td>\n",
              "      <td>45.10830</td>\n",
              "      <td>26.84939</td>\n",
              "      <td>-302.57328</td>\n",
              "      <td>-41.71932</td>\n",
              "      <td>-138.85034</td>\n",
              "      <td>...</td>\n",
              "      <td>28.55107</td>\n",
              "      <td>1.52298</td>\n",
              "      <td>70.99515</td>\n",
              "      <td>-43.63073</td>\n",
              "      <td>-42.55014</td>\n",
              "      <td>129.82848</td>\n",
              "      <td>79.95420</td>\n",
              "      <td>-87.14554</td>\n",
              "      <td>-45.75446</td>\n",
              "      <td>-65.82100</td>\n",
              "      <td>-43.90031</td>\n",
              "      <td>-19.45705</td>\n",
              "      <td>12.59163</td>\n",
              "      <td>-407.64130</td>\n",
              "      <td>42.91189</td>\n",
              "      <td>12.15850</td>\n",
              "      <td>-88.37882</td>\n",
              "      <td>42.25246</td>\n",
              "      <td>46.49209</td>\n",
              "      <td>-30.17747</td>\n",
              "      <td>45.98495</td>\n",
              "      <td>130.47892</td>\n",
              "      <td>13.88281</td>\n",
              "      <td>-4.00055</td>\n",
              "      <td>17.85965</td>\n",
              "      <td>-18.32138</td>\n",
              "      <td>-87.99109</td>\n",
              "      <td>14.37524</td>\n",
              "      <td>-22.70119</td>\n",
              "      <td>-58.81266</td>\n",
              "      <td>5.66812</td>\n",
              "      <td>-19.68073</td>\n",
              "      <td>33.04964</td>\n",
              "      <td>42.87836</td>\n",
              "      <td>-9.90378</td>\n",
              "      <td>-32.22788</td>\n",
              "      <td>70.49388</td>\n",
              "      <td>12.04941</td>\n",
              "      <td>58.43453</td>\n",
              "      <td>26.92061</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2001</td>\n",
              "      <td>50.95714</td>\n",
              "      <td>31.85602</td>\n",
              "      <td>55.81851</td>\n",
              "      <td>13.41693</td>\n",
              "      <td>-6.57898</td>\n",
              "      <td>-18.54940</td>\n",
              "      <td>-3.27872</td>\n",
              "      <td>-2.35035</td>\n",
              "      <td>16.07017</td>\n",
              "      <td>1.39518</td>\n",
              "      <td>2.73553</td>\n",
              "      <td>0.82804</td>\n",
              "      <td>7.46586</td>\n",
              "      <td>699.54544</td>\n",
              "      <td>1016.00954</td>\n",
              "      <td>594.06748</td>\n",
              "      <td>355.73663</td>\n",
              "      <td>507.39931</td>\n",
              "      <td>387.69910</td>\n",
              "      <td>287.15347</td>\n",
              "      <td>112.37152</td>\n",
              "      <td>161.68928</td>\n",
              "      <td>144.14353</td>\n",
              "      <td>199.29693</td>\n",
              "      <td>-4.24359</td>\n",
              "      <td>-297.00587</td>\n",
              "      <td>-148.36392</td>\n",
              "      <td>-7.94726</td>\n",
              "      <td>-18.71630</td>\n",
              "      <td>12.77542</td>\n",
              "      <td>-25.37725</td>\n",
              "      <td>9.71410</td>\n",
              "      <td>0.13843</td>\n",
              "      <td>26.79723</td>\n",
              "      <td>6.30760</td>\n",
              "      <td>28.70107</td>\n",
              "      <td>-74.89005</td>\n",
              "      <td>-289.19553</td>\n",
              "      <td>-166.26089</td>\n",
              "      <td>...</td>\n",
              "      <td>18.50939</td>\n",
              "      <td>16.97216</td>\n",
              "      <td>24.26629</td>\n",
              "      <td>-10.50788</td>\n",
              "      <td>-8.68412</td>\n",
              "      <td>54.75759</td>\n",
              "      <td>194.74034</td>\n",
              "      <td>7.95966</td>\n",
              "      <td>-18.22685</td>\n",
              "      <td>0.06463</td>\n",
              "      <td>-2.63069</td>\n",
              "      <td>26.02561</td>\n",
              "      <td>1.75729</td>\n",
              "      <td>-262.36917</td>\n",
              "      <td>-233.60089</td>\n",
              "      <td>-2.50502</td>\n",
              "      <td>-12.14279</td>\n",
              "      <td>81.37617</td>\n",
              "      <td>2.07554</td>\n",
              "      <td>-1.82381</td>\n",
              "      <td>183.65292</td>\n",
              "      <td>22.64797</td>\n",
              "      <td>-39.98887</td>\n",
              "      <td>43.37381</td>\n",
              "      <td>-31.56737</td>\n",
              "      <td>-4.88840</td>\n",
              "      <td>-36.53213</td>\n",
              "      <td>-23.94662</td>\n",
              "      <td>-84.19275</td>\n",
              "      <td>66.00518</td>\n",
              "      <td>3.03800</td>\n",
              "      <td>26.05866</td>\n",
              "      <td>-50.92779</td>\n",
              "      <td>10.93792</td>\n",
              "      <td>-0.07568</td>\n",
              "      <td>43.20130</td>\n",
              "      <td>-115.00698</td>\n",
              "      <td>-0.05859</td>\n",
              "      <td>39.67068</td>\n",
              "      <td>-0.66345</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2001</td>\n",
              "      <td>48.24750</td>\n",
              "      <td>-1.89837</td>\n",
              "      <td>36.29772</td>\n",
              "      <td>2.58776</td>\n",
              "      <td>0.97170</td>\n",
              "      <td>-26.21683</td>\n",
              "      <td>5.05097</td>\n",
              "      <td>-10.34124</td>\n",
              "      <td>3.55005</td>\n",
              "      <td>-6.36304</td>\n",
              "      <td>6.63016</td>\n",
              "      <td>-3.35142</td>\n",
              "      <td>37.64085</td>\n",
              "      <td>2174.08189</td>\n",
              "      <td>697.43346</td>\n",
              "      <td>459.24587</td>\n",
              "      <td>742.78961</td>\n",
              "      <td>229.30783</td>\n",
              "      <td>387.89697</td>\n",
              "      <td>249.06662</td>\n",
              "      <td>245.89870</td>\n",
              "      <td>176.20527</td>\n",
              "      <td>98.82222</td>\n",
              "      <td>150.97286</td>\n",
              "      <td>78.49057</td>\n",
              "      <td>-62.00282</td>\n",
              "      <td>43.49659</td>\n",
              "      <td>-96.42719</td>\n",
              "      <td>-108.96608</td>\n",
              "      <td>14.22854</td>\n",
              "      <td>14.54178</td>\n",
              "      <td>-23.55608</td>\n",
              "      <td>-39.36953</td>\n",
              "      <td>-43.59209</td>\n",
              "      <td>20.83714</td>\n",
              "      <td>35.63919</td>\n",
              "      <td>-181.34947</td>\n",
              "      <td>-93.66614</td>\n",
              "      <td>-90.55616</td>\n",
              "      <td>...</td>\n",
              "      <td>4.56917</td>\n",
              "      <td>-37.32280</td>\n",
              "      <td>4.15159</td>\n",
              "      <td>12.24315</td>\n",
              "      <td>35.02697</td>\n",
              "      <td>-178.89573</td>\n",
              "      <td>82.46573</td>\n",
              "      <td>-20.49425</td>\n",
              "      <td>101.78577</td>\n",
              "      <td>-19.77808</td>\n",
              "      <td>-21.52657</td>\n",
              "      <td>3.36303</td>\n",
              "      <td>-11.63176</td>\n",
              "      <td>51.55411</td>\n",
              "      <td>-50.57576</td>\n",
              "      <td>-28.14755</td>\n",
              "      <td>-83.15795</td>\n",
              "      <td>-7.35260</td>\n",
              "      <td>-22.11505</td>\n",
              "      <td>1.18279</td>\n",
              "      <td>-122.70467</td>\n",
              "      <td>150.57360</td>\n",
              "      <td>24.37468</td>\n",
              "      <td>41.19821</td>\n",
              "      <td>-37.04318</td>\n",
              "      <td>-28.72986</td>\n",
              "      <td>162.19614</td>\n",
              "      <td>22.18309</td>\n",
              "      <td>-8.63509</td>\n",
              "      <td>85.23416</td>\n",
              "      <td>34.57337</td>\n",
              "      <td>-171.70734</td>\n",
              "      <td>-16.96705</td>\n",
              "      <td>-46.67617</td>\n",
              "      <td>-12.51516</td>\n",
              "      <td>82.58061</td>\n",
              "      <td>-72.08993</td>\n",
              "      <td>9.90558</td>\n",
              "      <td>199.62971</td>\n",
              "      <td>18.85382</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2001</td>\n",
              "      <td>50.97020</td>\n",
              "      <td>42.20998</td>\n",
              "      <td>67.09964</td>\n",
              "      <td>8.46791</td>\n",
              "      <td>-15.85279</td>\n",
              "      <td>-16.81409</td>\n",
              "      <td>-12.48207</td>\n",
              "      <td>-9.37636</td>\n",
              "      <td>12.63699</td>\n",
              "      <td>0.93609</td>\n",
              "      <td>1.60923</td>\n",
              "      <td>2.19223</td>\n",
              "      <td>47.32082</td>\n",
              "      <td>894.28471</td>\n",
              "      <td>809.86615</td>\n",
              "      <td>318.78559</td>\n",
              "      <td>435.04497</td>\n",
              "      <td>341.61467</td>\n",
              "      <td>334.30734</td>\n",
              "      <td>322.99589</td>\n",
              "      <td>190.61921</td>\n",
              "      <td>235.84715</td>\n",
              "      <td>96.89517</td>\n",
              "      <td>210.58870</td>\n",
              "      <td>5.60463</td>\n",
              "      <td>-199.63958</td>\n",
              "      <td>204.85812</td>\n",
              "      <td>-77.17695</td>\n",
              "      <td>-65.79741</td>\n",
              "      <td>-6.95097</td>\n",
              "      <td>-12.15262</td>\n",
              "      <td>-3.85410</td>\n",
              "      <td>20.68990</td>\n",
              "      <td>-20.30480</td>\n",
              "      <td>37.15045</td>\n",
              "      <td>11.20673</td>\n",
              "      <td>-124.09519</td>\n",
              "      <td>-295.98542</td>\n",
              "      <td>-33.31169</td>\n",
              "      <td>...</td>\n",
              "      <td>45.25506</td>\n",
              "      <td>10.42226</td>\n",
              "      <td>27.88782</td>\n",
              "      <td>-17.12676</td>\n",
              "      <td>-31.54772</td>\n",
              "      <td>-76.86293</td>\n",
              "      <td>41.17343</td>\n",
              "      <td>-138.32535</td>\n",
              "      <td>-53.96905</td>\n",
              "      <td>-21.30266</td>\n",
              "      <td>-24.87362</td>\n",
              "      <td>-2.46595</td>\n",
              "      <td>-4.05003</td>\n",
              "      <td>-56.51161</td>\n",
              "      <td>-34.56445</td>\n",
              "      <td>-5.07092</td>\n",
              "      <td>-47.75605</td>\n",
              "      <td>64.81513</td>\n",
              "      <td>-97.42948</td>\n",
              "      <td>-12.59418</td>\n",
              "      <td>55.23699</td>\n",
              "      <td>28.85657</td>\n",
              "      <td>54.53513</td>\n",
              "      <td>-31.97077</td>\n",
              "      <td>20.03279</td>\n",
              "      <td>-8.07892</td>\n",
              "      <td>-55.12617</td>\n",
              "      <td>26.58961</td>\n",
              "      <td>-10.27183</td>\n",
              "      <td>-30.64232</td>\n",
              "      <td>9.92661</td>\n",
              "      <td>-55.95724</td>\n",
              "      <td>64.92712</td>\n",
              "      <td>-17.72522</td>\n",
              "      <td>-1.49237</td>\n",
              "      <td>-7.50035</td>\n",
              "      <td>51.76631</td>\n",
              "      <td>7.88713</td>\n",
              "      <td>55.66926</td>\n",
              "      <td>28.74903</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 91 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "     0         1         2         3   ...         87        88         89        90\n",
              "0  2001  49.94357  21.47114  73.07750  ...   68.40795  -1.82223  -27.46348   2.26327\n",
              "1  2001  48.73215  18.42930  70.32679  ...   70.49388  12.04941   58.43453  26.92061\n",
              "2  2001  50.95714  31.85602  55.81851  ... -115.00698  -0.05859   39.67068  -0.66345\n",
              "3  2001  48.24750  -1.89837  36.29772  ...  -72.08993   9.90558  199.62971  18.85382\n",
              "4  2001  50.97020  42.20998  67.09964  ...   51.76631   7.88713   55.66926  28.74903\n",
              "\n",
              "[5 rows x 91 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n4wnRJT1778j"
      },
      "source": [
        "X = df.iloc[:, 1:].values\n",
        "y = df.iloc[:, 0].values\n",
        "\n",
        "train_size = 463715\n",
        "x_train = X[:train_size, :]\n",
        "y_train = y[:train_size]\n",
        "x_test = X[train_size:, :]\n",
        "y_test = y[train_size:]"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_386JE_o5gOd"
      },
      "source": [
        "## Задание 0. (0 баллов, но при невыполнении максимум за все задание &mdash; 0 баллов)\n",
        "\n",
        "Мы будем использовать RMSE как метрику качества. Для самого первого бейзлайна обучите `Ridge` регрессию из `sklearn`. Кроме того, посчитайте качество при наилучшем константном прогнозе."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "otwuisa56MLr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2031e12f-54f1-4b48-c5d8-f8e737e67fa8"
      },
      "source": [
        "from sklearn.linear_model import Ridge\n",
        "from sklearn.metrics import mean_squared_error as mse\n",
        "\n",
        "ridge = Ridge()\n",
        "ridge.fit(x_train, y_train)\n",
        "mse(y_test, ridge.predict(x_test), squared=False)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "9.510160711373395"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8J0ewumLVHO7",
        "outputId": "1d2851e4-8bed-407e-af00-4002044c273d"
      },
      "source": [
        "from math import sqrt\n",
        "from scipy.stats import mode \n",
        "\n",
        "print('предсказание средним значением', sqrt(((y_test - y_train.mean()) ** 2).mean()))\n",
        "print('предсказание модой', sqrt(((y_test - mode(y_train)[0][0]) ** 2).mean()))\n",
        "print('предсказание медианой', sqrt(((y_test - np.median(y_train)) ** 2).mean()))"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "предсказание средним значением 10.85246390513634\n",
            "предсказание модой 13.787170630263175\n",
            "предсказание медианой 11.403668567118597\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_6ilBKYt6OdD"
      },
      "source": [
        "## Задание 1. (максимум 10 баллов)\n",
        "\n",
        "Реализуйте обучение и тестирование нейронной сети для предоставленного вам набора данных. Соотношение между полученным значением метрики на тестовой выборке и баллами за задание следующее:\n",
        "\n",
        "- $\\text{RMSE} \\le 9.00 $ &mdash; 4 балла\n",
        "- $\\text{RMSE} \\le 8.90 $ &mdash; 6 баллов\n",
        "- $\\text{RMSE} \\le 8.80 $ &mdash; 8 баллов\n",
        "- $\\text{RMSE} \\le 8.75 $ &mdash; 10 баллов\n",
        "\n",
        "Есть несколько правил, которых вам нужно придерживаться:\n",
        "\n",
        "- Весь пайплайн обучения должен быть написан на PyTorch. При этом вы можете пользоваться другими библиотеками (`numpy`, `sklearn` и пр.), но только для обработки данных. То есть как угодно трансформировать данные и считать метрики с помощью этих библиотек можно, а импортировать модели из `sklearn` и выбивать с их помощью требуемое качество &mdash; нельзя. Также нельзя пользоваться библиотеками, для которых сам PyTorch является зависимостью.\n",
        "\n",
        "- Мы никак не ограничиваем ваш выбор архитектуры модели, но скорее всего вам будет достаточно полносвязной нейронной сети.\n",
        "\n",
        "- Для обучения запрещается использовать какие-либо иные данные, кроме обучающей выборки.\n",
        "\n",
        "- Ансамблирование моделей запрещено.\n",
        "\n",
        "### Полезные советы:\n",
        "\n",
        "- Очень вряд ли, что у вас с первого раза получится выбить качество на 10 баллов, поэтому пробуйте разные архитектуры, оптимизаторы и значения гиперпараметров. В идеале при запуске каждого нового эксперимента вы должны менять что-то одно, чтобы точно знать, как этот фактор влияет на качество.\n",
        "\n",
        "- Тот факт, что мы занимаемся глубинным обучением, не означает, что стоит забывать про приемы, использующиеся в классическом машинном обучении. Так что обязательно проводите исследовательский анализ данных, отрисовывайте нужные графики и не забывайте про масштабирование и подбор гиперпараметров.\n",
        "\n",
        "- Вы наверняка столкнетесь с тем, что ваша нейронная сеть будет сильно переобучаться. Для нейросетей существуют специальные методы регуляризации, например, dropout ([статья](https://jmlr.org/papers/volume15/srivastava14a/srivastava14a.pdf)) и weight decay ([блогпост](https://towardsdatascience.com/weight-decay-l2-regularization-90a9e17713cd)). Они, разумеется, реализованы в PyTorch. Попробуйте поэкспериментировать с ними.\n",
        "\n",
        "- Если вы чего-то не знаете, не гнушайтесь гуглить. В интернете очень много полезной информации, туториалов и советов по глубинному обучению в целом и по PyTorch в частности. Но не забывайте, что за скатанный код без ссылки на источник придется ответить по всей строгости!\n",
        "\n",
        "- Если вы сразу реализуете обучение на GPU, то у вас будет больше времени на эксперименты, так как любые вычисления будут работать быстрее. Google Colab предоставляет несколько GPU-часов (обычно около 8-10) в сутки бесплатно.\n",
        "\n",
        "- Чтобы отладить код, можете обучаться на небольшой части данных или даже на одном батче. Если лосс на обучающей выборке не падает, то что-то точно идет не так!\n",
        "\n",
        "- Пользуйтесь утилитами, которые вам предоставляет PyTorch (например, Dataset и Dataloader). Их специально разработали для упрощения разработки пайплайна обучения.\n",
        "\n",
        "- Скорее всего вы захотите отслеживать прогресс обучения. Для создания прогресс-баров есть удобная библиотека `tqdm`.\n",
        "\n",
        "- Быть может, вы захотите, чтобы графики рисовались прямо во время обучения. Можете воспользоваться функцией [clear_output](http://ipython.org/ipython-doc/dev/api/generated/IPython.display.html#IPython.display.clear_output), чтобы удалять старый график и рисовать новый на его месте.\n",
        "\n",
        "**ОБЯЗАТЕЛЬНО** рисуйте графики зависимости лосса/метрики на обучающей и тестовой выборках в зависимости от времени обучения. Если обучение занимает относительно небольшое число эпох, то лучше рисовать зависимость от номера шага обучения, если же эпох больше, то рисуйте зависимость по эпохам. Если проверяющий не увидит такого графика для вашей лучшей модели, то он в праве снизить баллы за задание.\n",
        "\n",
        "**ВАЖНО!** Ваше решение должно быть воспроизводимым. Если это не так, то проверяющий имеет право снизить баллы за задание. Чтобы зафиксировать random seed, воспользуйтесь функцией из ячейки ниже.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VaMButDmEKKw"
      },
      "source": [
        "def set_random_seed(seed):\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    random.seed(seed)\n",
        "\n",
        "set_random_seed(10)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TZW0gMe3vT8u"
      },
      "source": [
        "Вы можете придерживаться любой адекватной струкуры кода, но мы советуем воспользоваться следующими сигнатурами функций. Лучше всего, если вы проверите ваши предсказания ассертом: так вы убережете себя от разных косяков, например, что вектор предсказаний состоит из всего одного числа. В любом случае, внимательно следите за тем, для каких тензоров вы считаете метрику RMSE. При случайном или намеренном введении в заблуждение проверяющие очень сильно разозлятся."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "kdgUwZRl9Czo",
        "outputId": "352340b5-cee0-4175-c0b4-be33f3085d75"
      },
      "source": [
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "device"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'cuda'"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JNaVOwLf-Gj-"
      },
      "source": [
        "# c семинара\n",
        "\n",
        "class Dataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, x, y):\n",
        "        self.x = x\n",
        "        self.y = y\n",
        "        \n",
        "    def __len__(self):\n",
        "        return len(self.x)\n",
        "    \n",
        "    def __getitem__(self, idx):\n",
        "        return {\"sample\": torch.tensor(self.x[idx, :], dtype=torch.float), \n",
        "                \"target\": torch.tensor(self.y[idx], dtype=torch.float)}"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VBNmX_Iz9NRb"
      },
      "source": [
        "class Scaler:\n",
        "\n",
        "    def __init__(self):\n",
        "        self.max = None\n",
        "        self.min = None\n",
        "\n",
        "    def fit(self, v):\n",
        "        self.max = torch.max(v, axis=0).values #float(torch.max(v)) # v.max(axis=0)\n",
        "        self.min = torch.min(v, axis=0).values # float(torch.max(v)) # v.min(axis=0)\n",
        "\n",
        "    def transform(self, v):\n",
        "        return (v - self.min) / (self.max - self.min)\n",
        "\n",
        "    def inverse_transform(self, v):\n",
        "        return v * (self.max - self.min) + self.min"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bieES6Ma9SMv"
      },
      "source": [
        "x_train, y_train = torch.tensor(x_train, dtype=torch.float32).to(device), torch.tensor(y_train, dtype=torch.float32).to(device)\n",
        "x_test, y_test = torch.tensor(x_test, dtype=torch.float32).to(device), torch.tensor(y_test, dtype=torch.float32).to(device)\n",
        "\n",
        "x_train_scaler = Scaler()\n",
        "x_train_scaler.fit(x_train)\n",
        "x_train = x_train_scaler.transform(x_train)\n",
        "x_test = x_train_scaler.transform(x_test)\n",
        "\n",
        "y_train_scaler = Scaler()\n",
        "y_train_scaler.fit(y_train)\n",
        "y_train = y_train_scaler.transform(y_train)\n",
        "y_test = y_train_scaler.transform(y_test)"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kdstLGCw-LGg"
      },
      "source": [
        "def RMSE(yhat, y):\n",
        "    return torch.sqrt(nn.functional.mse_loss(yhat, y))"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "peomNjMWbkSz"
      },
      "source": [
        "train_set = Dataset(x_train, y_train)\n",
        "train_loader = torch.utils.data.DataLoader(train_set, batch_size=8000, shuffle=True)\n",
        "\n",
        "test_set = Dataset(x_test, y_test)\n",
        "test_loader = torch.utils.data.DataLoader(test_set, batch_size=8000, shuffle=False)\n",
        "\n",
        "model = nn.Sequential(\n",
        "    nn.Linear(90, 100),\n",
        "    nn.ReLU(),\n",
        "    nn.Dropout(),\n",
        "    nn.BatchNorm1d(100),\n",
        "    nn.Linear(100, 200),\n",
        "    nn.ReLU(),\n",
        "    nn.Dropout(),\n",
        "    nn.BatchNorm1d(200),\n",
        "    nn.Linear(200, 1)\n",
        ")\n",
        "\n",
        "model.to(device)\n",
        "\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=1e-5, momentum=0.9)\n",
        "criterion =  RMSE"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Wmxrf5Qveux"
      },
      "source": [
        "from tqdm import tqdm\n",
        "from IPython.display import clear_output\n",
        "from matplotlib import pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "def train(model, optimizer, criterion, train_loader, test_loader):\n",
        "    '''\n",
        "    params:\n",
        "        model - torch.nn.Module to be fitted\n",
        "        optimizer - model optimizer\n",
        "        criterion - loss function from torch.nn\n",
        "        train_loader - torch.utils.data.Dataloader with train set\n",
        "        test_loader - torch.utils.data.Dataloader with test set\n",
        "                      (if you wish to validate during training)\n",
        "    '''\n",
        "\n",
        "    num_epoch = 35\n",
        "    epoch = 0\n",
        "\n",
        "    train_losses = []\n",
        "    test_losses = []\n",
        "\n",
        "    for epoch in range(num_epoch):\n",
        "\n",
        "        epoch += 1\n",
        "\n",
        "        model.train()\n",
        "        train_loss = 0\n",
        "        for batch in tqdm(train_loader):\n",
        "            y_pred = model(batch['sample'])\n",
        "            loss = criterion(y_train_scaler.inverse_transform(y_pred), \n",
        "                             y_train_scaler.inverse_transform(batch['target']).view(y_train_scaler.inverse_transform(batch['target']).shape[0], 1))\n",
        "            # loss = criterion(y_pred, batch['target']) ** (y_train_scaler.max - y_train_scaler.min)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            optimizer.zero_grad()\n",
        "            train_loss += loss ** 2 * len(y_pred)\n",
        "\n",
        "        train_loss = torch.sqrt(train_loss / len(train_set))\n",
        "        train_losses.append(float(train_loss))\n",
        "\n",
        "        model.eval()\n",
        "        test_loss = 0\n",
        "        for batch in tqdm(test_loader):\n",
        "            y_pred = model(batch['sample'])\n",
        "            loss = criterion(y_train_scaler.inverse_transform(y_pred), \n",
        "                             y_train_scaler.inverse_transform(batch['target']).view(y_train_scaler.inverse_transform(batch['target']).shape[0], 1))\n",
        "            # loss = criterion(y_pred, batch['target']) ** (y_train_scaler.max - y_train_scaler.min)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            optimizer.zero_grad()\n",
        "            test_loss += loss ** 2 * len(y_pred)\n",
        "\n",
        "        test_loss = torch.sqrt(train_loss / len(train_set))\n",
        "        test_losses.append(float(train_loss))\n",
        "\n",
        "        clear_output(True)\n",
        "        fig, axes = plt.subplots(1, 2, figsize=(15, 5), sharey=False)\n",
        "        sns.lineplot(x=np.arange(len(train_losses) -2 ), y=train_losses[2:], ax=axes[0])\n",
        "        axes[0].set_title('Зависимость rmse от количества эпох (трейн)')\n",
        "        sns.lineplot(x=np.arange(len(train_losses) - 2), y=test_losses[2:], ax=axes[1])\n",
        "        axes[1].set_title('Зависимость rmse от количества эпох (тест)')\n",
        "        plt.show()\n",
        "        print(f'epoch {epoch + 1}', #' out of {num_epoch}\\n', \n",
        "              '\\ntrain loss', train_losses[-1],\n",
        "              '\\ntest loss', test_losses[-1])\n",
        "        \n",
        "    return train_losses, test_losses\n",
        "\n",
        "\n",
        "def test(model, criterion, test_loader):\n",
        "    '''\n",
        "    params:\n",
        "        model - torch.nn.Module to be evaluated on test set\n",
        "        criterion - loss function from torch.nn\n",
        "        test_loader - torch.utils.data.Dataloader with test set\n",
        "    ----------\n",
        "    returns:\n",
        "        predicts - torch.tensor with shape (len(test_loader.dataset), ),\n",
        "                   which contains predictions for test objects\n",
        "    '''\n",
        "    model.eval()\n",
        "\n",
        "    predicts = torch.tensor([]).to(device)\n",
        "    test_loss = 0\n",
        "\n",
        "    for batch in test_loader:\n",
        "        y_pred = model(batch['sample'])\n",
        "        loss = criterion(y_train_scaler.inverse_transform(y_pred), \n",
        "                          y_train_scaler.inverse_transform(batch['target']))\n",
        "        # loss = criterion(y_pred, batch['target']) ** (y_train_scaler.max - y_train_scaler.min)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        optimizer.zero_grad()\n",
        "        test_loss += loss ** 2 * len(y_pred)\n",
        "        predicts = torch.cat((predicts, y_pred), 0)\n",
        "\n",
        "    print('Test RMSE:', float(test_loss / len(test_loader)))\n",
        "\n",
        "    return predicts"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 385
        },
        "id": "lomt3JdnQKsz",
        "outputId": "1d4ec930-f5d4-4ce8-89a8-8bb1ee9c513a"
      },
      "source": [
        "train_losses, test_losses = train(model, optimizer, criterion, train_loader, test_loader)"
      ],
      "execution_count": 120,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1080x360 with 2 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 35 \n",
            "train loss 9.059384200344912 \n",
            "test loss 8.896711957114773\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 312
        },
        "id": "fEO_nNv1PP3q",
        "outputId": "ee4b4ac1-9918-4259-9a93-65b565d4c2c6"
      },
      "source": [
        "model.eval()\n",
        "\n",
        "print('test quality:  ',\n",
        "float(criterion(y_train_scaler.inverse_transform(model(x_test)),\n",
        "y_train_scaler.inverse_transform(y_test).view(y_train_scaler.inverse_transform(y_test).shape[0], 1)).data))\n",
        "\n",
        "indices = np.random.randint(low=0, high=x_test.size()[0], size=100)\n",
        "predictions = model(x_test[indices])\n",
        "ax = sns.histplot(x=[float(i.data) for i in predictions], kde='line', \n",
        "                  label='preds', color='black')\n",
        "sns.histplot(x=[float(i.data) for i in y_test[indices]], kde='line', ax=ax, \n",
        "             color='pink', label='real')\n",
        "plt.show()"
      ],
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "rmse test: 8.896711957114773\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4PVEXDgD6Swj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "da552b69-0157-444f-f5bd-2ab6b69dd772"
      },
      "source": [
        "assert test(model, criterion, test_loader).shape[0] == y_test.shape[0]"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test RMSE: 8.896711957114773\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bine9EES6TIn"
      },
      "source": [
        "## Задание 2. (0 баллов, но при невыполнении максимум за все задание &mdash; 0 баллов)\n",
        "\n",
        "Напишите небольшой отчет о том, как вы добились полученного качества: какие средства использовали и какие эксперименты проводили. Подробно расскажите об архитектурах и значениях гиперпараметров, а также какие метрики на тесте они показывали. Чтобы отчет был зачтен, необходимо привести хотя бы 3 эксперимента."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "acXwXuf-XXp4"
      },
      "source": [
        "1. до масштабирования данных модель давала совершенно дурацкие предсказания, это скорее всего было связано с тем, что одни признаки затмевали другие. исправив это обстоятельво скалированием, точность стала лучше в десятки раз\n",
        "\n",
        "2. модель давала близкий к константе прогноз. на это влияет распределение таргета, у нас оно очень skewed, что располагает к околоконстантным прогнозам. batchnorm помогает хотя бы на уровне батча поправить распределение, чем помог лично моей модели преодолет константный порог\n",
        "\n",
        "3. dropout помог избежать переобучения: когда были настроены масштабы данных и батчнормализация, модель сходилась, но с существенной разницей между рмсе на тесте и трейне (до 2-3 единиц). дропаут позволил сократить между ними дистанцию, но снизил скорость обучения\n",
        "\n",
        "4. из-за того, что рядом с константным прогнозом скорость улучшения рмсе сильно падает, я выбрала в качестве градиентного спуска моментум, так как он позволяет игнорировать небольшие флуктуации, опираясь на предыдущий (в основном правильный) градиент. я взяла довольно большой коэфф инерции, и чтобы это не превратилось в ситуацию, где я до конца жизни буду двигаться градиентом, посчитанным с самого начала, я взяла более маленький lr \n",
        "\n",
        "батч норм, количество нейронов и слоев выбиралось по зову сердца и по посту в канале ОГО"
      ]
    }
  ]
}